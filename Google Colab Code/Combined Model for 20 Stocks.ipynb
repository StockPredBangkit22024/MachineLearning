{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **HYPERPARAMETER TUNING - GOOGLE COLAB CODE**\n",
        "\n",
        "**Bangkit Academy 2024 Batch 2 - MSIB 7**\n",
        "\n",
        "**Team ID : C242-PS012**\n",
        "\n",
        "**Team Member [Machine Learning] :**\n",
        "\n",
        "**1. M296B4KY3091  –  Muhammad Sulthon  Haqiqi  –  Universitas  Pembangunan Nasional Veteran Jawa Timur**\n",
        "\n",
        "**2. M007B4KY3020    –    Muhammad   Rakha    Almasah    –    Universitas    Dian Nuswantoro**\n",
        "\n",
        "**3. M123B4KY0062   –   Achmad   Zahir   Wajdi   –  Politeknik   Elektronika   Negeri Surabaya**"
      ],
      "metadata": {
        "id": "-s-zHIxXFlZ6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installing Keras Tuner"
      ],
      "metadata": {
        "id": "m-eCwRgFo5GU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LixHUPdVD0LC"
      },
      "outputs": [],
      "source": [
        "!pip install -q -U keras-tuner"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Necessary Libraries"
      ],
      "metadata": {
        "id": "lS8WeqLro8wZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z7crHtae-rqd"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import tempfile\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras import regularizers\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import keras_tuner as kt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load and Display Combined Data"
      ],
      "metadata": {
        "id": "MJyxD2pZpH-I"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cTuMznhwBMtX"
      },
      "outputs": [],
      "source": [
        "data_gabungan = pd.read_csv('/content/data_gabungan.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mSLNOrIyAhyL"
      },
      "outputs": [],
      "source": [
        "data_gabungan.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define Features (X) and Targets (Y)"
      ],
      "metadata": {
        "id": "ySL8ma56pSZy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BbJi5RXjBHAB"
      },
      "outputs": [],
      "source": [
        "X = data_gabungan[['Close USDIDR', 'BI Rate', 'Inflasi']].values\n",
        "\n",
        "Y = data_gabungan[['Close CTRA', 'Close INDF', 'Close ASII', 'Close BSDE',\n",
        "                 'Close ICBP', 'Close KLBF', 'Close ITMG', 'Close JPFA',\n",
        "                 'Close TLKM', 'Close ULTJ', 'Close ACES', 'Close TSPC',\n",
        "                  'Close SMAR', 'Close SMSM', 'Close JRPT', 'Close DUTI',\n",
        "                   'Close EPMT', 'Close SMCB', 'Close PWON', 'Close JSMR']].values"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Split Data into Training and Validation Sets and Standardize"
      ],
      "metadata": {
        "id": "s64VFZpqpUmQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i8M3Ma0CBUDu"
      },
      "outputs": [],
      "source": [
        "# 70% Train, 30% Val\n",
        "total_ukuran_data = len(X)\n",
        "ukuran_data_pelatihan = int(0.70 * total_ukuran_data)\n",
        "\n",
        "X_Latih, Y_Latih = X[:ukuran_data_pelatihan], Y[:ukuran_data_pelatihan]\n",
        "X_Validasi, Y_Validasi = X[ukuran_data_pelatihan:], Y[ukuran_data_pelatihan:]\n",
        "\n",
        "skala_X = StandardScaler()\n",
        "X_Latih_Standarisasi = skala_X.fit_transform(X_Latih)\n",
        "X_Validasi_Standarisasi = skala_X.transform(X_Validasi)\n",
        "\n",
        "skala_Y = StandardScaler()\n",
        "Y_Latih_Standarisasi = skala_Y.fit_transform(Y_Latih)\n",
        "Y_Validasi_Standarisasi = skala_Y.transform(Y_Validasi)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Defining a Hyperparameter-Tuned Model Builder Function"
      ],
      "metadata": {
        "id": "fsLzRqkIpbj0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nxQr-YSjE-2j"
      },
      "outputs": [],
      "source": [
        "def model_builder(hp):\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(tf.keras.layers.Input(shape=(X_Latih.shape[1],)))\n",
        "\n",
        "    for i in range(3):\n",
        "        hp_units = hp.Int(f'units_{i}', min_value=64, max_value=512, step=32)\n",
        "\n",
        "        hp_kernel_regularizer = hp.Float(f'kernel_regularizer_{i}', min_value=1e-6, max_value=1e-2, sampling='log')\n",
        "\n",
        "        model.add(tf.keras.layers.Dense(units=hp_units, activation='relu',\n",
        "                                        kernel_regularizer=regularizers.l2(hp_kernel_regularizer)))\n",
        "        model.add(tf.keras.layers.BatchNormalization())\n",
        "        model.add(tf.keras.layers.Dropout(hp.Float(f'dropout_{i}', 0.2, 0.5, step=0.1)))\n",
        "\n",
        "    model.add(tf.keras.layers.Dense(20, activation='relu'))\n",
        "\n",
        "    hp_learning_rate = hp.Float('learning_rate', min_value=1e-5, max_value=1e-2, sampling='log')\n",
        "\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
        "                  loss='mse', metrics=['mae'])\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initializing the Hyperband Tuner for Model Optimization"
      ],
      "metadata": {
        "id": "ddzXFZqKpfWo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N8YNWLDpFCIA"
      },
      "outputs": [],
      "source": [
        "tuner = kt.Hyperband(model_builder,\n",
        "                     objective='val_loss',\n",
        "                     max_epochs=1000,\n",
        "                     factor=3,\n",
        "                     directory='my_dir',\n",
        "                     project_name='stock_price_prediction')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setting Up Early Stopping Callback"
      ],
      "metadata": {
        "id": "iy1n4wwRpi-l"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5hTINNqTFFmz"
      },
      "outputs": [],
      "source": [
        "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=25)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Running Hyperparameter Tuning with the Hyperband Tuner"
      ],
      "metadata": {
        "id": "LPHrCGPzpnlX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_i3tYtC_B5rj"
      },
      "outputs": [],
      "source": [
        "tuner.search(X_Latih_Standarisasi, Y_Latih_Standarisasi,\n",
        "             validation_data=(X_Validasi_Standarisasi, Y_Validasi_Standarisasi),\n",
        "             epochs=10000, callbacks=[stop_early])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Retrieving and Displaying the Best Hyperparameters from Tuning Results"
      ],
      "metadata": {
        "id": "7pFW5mr3ptcG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B5jogTfIJJ4V"
      },
      "outputs": [],
      "source": [
        "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P8-a9jTcJNxh"
      },
      "outputs": [],
      "source": [
        "print(f\"Optimal units: {best_hps.get('units_0')}, {best_hps.get('units_1')}, {best_hps.get('units_2')}\")\n",
        "print(f\"Optimal dropout: {best_hps.get('dropout_0')}, {best_hps.get('dropout_1')}, {best_hps.get('dropout_2')}\")\n",
        "print(f\"Optimal kernel_regularizer: {best_hps.get('kernel_regularizer_0')}, {best_hps.get('kernel_regularizer_1')}, {best_hps.get('kernel_regularizer_2')}\")\n",
        "print(f\"Optimal learning rate: {best_hps.get('learning_rate')}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Building and Displaying the Summary of the Optimized Model"
      ],
      "metadata": {
        "id": "xNde1SM1pvO0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BUNyryd8BWdU"
      },
      "outputs": [],
      "source": [
        "model = tuner.hypermodel.build(best_hps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4mmPMB1b4x5a"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setting Up Model Checkpointing to Save the Best Model"
      ],
      "metadata": {
        "id": "SnQ_MIiSp-I9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W1DWT_RmtlWV"
      },
      "outputs": [],
      "source": [
        "checkpoint_filepath = 'model_terbaik.keras'\n",
        "checkpoint = ModelCheckpoint(filepath=checkpoint_filepath,\n",
        "                             monitor='val_loss',\n",
        "                             save_best_only=True,\n",
        "                             mode='min')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training the Model with Checkpointing and Validation Data"
      ],
      "metadata": {
        "id": "Hf3we_YAqBnp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f6fcSQbqtq6l"
      },
      "outputs": [],
      "source": [
        "history = model.fit(X_Latih_Standarisasi, Y_Latih_Standarisasi,\n",
        "                    validation_data=(X_Validasi_Standarisasi, Y_Validasi_Standarisasi),\n",
        "                    epochs=5000,\n",
        "                    batch_size=32,\n",
        "                    callbacks=[checkpoint])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plotting Training and Validation Loss Over Epochs"
      ],
      "metadata": {
        "id": "jN_MkZVmqG2S"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EmIqkVQftv-y"
      },
      "outputs": [],
      "source": [
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs_range = range(1, len(loss) + 1)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(epochs_range, loss, label='Training Loss', color='blue')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss', color='red')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss (MSE)')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading the Best Model from Checkpoint"
      ],
      "metadata": {
        "id": "rCK9QOxWqNPW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ba0lJTA3ttBc"
      },
      "outputs": [],
      "source": [
        "model_terbaik = tf.keras.models.load_model(checkpoint_filepath)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_terbaik.evaluate(X_Validasi_Standarisasi,Y_Validasi_Standarisasi)"
      ],
      "metadata": {
        "id": "ktaSZ8jOc92k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Making Predictions on New Data and Displaying Stock Prices"
      ],
      "metadata": {
        "id": "5BV00IIFqQgP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SeaXBqYfyjSy"
      },
      "outputs": [],
      "source": [
        "data_baru = np.array([[15569.15, 6.25, 2.12]])\n",
        "data_baru_standarisasi = skala_X.transform(data_baru)\n",
        "\n",
        "prediksi_standarisasi = model_terbaik.predict(data_baru_standarisasi)\n",
        "prediksi = skala_Y.inverse_transform(prediksi_standarisasi)\n",
        "\n",
        "saham = ['Close CTRA', 'Close INDF', 'Close ASII', 'Close BSDE', 'Close ICBP',\n",
        "          'Close KLBF', 'Close ITMG', 'Close JPFA', 'Close TLKM', 'Close ULTJ','Close ACES', 'Close TSPC',\n",
        "          'Close SMAR', 'Close SMSM', 'Close JRPT', 'Close DUTI', 'Close EPMT', 'Close SMCB', 'Close PWON', 'Close JSMR']\n",
        "hasil_prediksi = dict(zip(saham, prediksi[0]))\n",
        "\n",
        "print(\"Prediksi Harga Saham Berdasarkan Data Baru:\")\n",
        "for stock, price in hasil_prediksi.items():\n",
        "    print(f\"{stock}: {price:.2f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Saving Standard Scalers to Disk Using Joblib"
      ],
      "metadata": {
        "id": "lhTQ1ilCqUjr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lN6URUQWE36V"
      },
      "outputs": [],
      "source": [
        "import joblib\n",
        "joblib.dump(skala_X, 'skala_X.pkl')\n",
        "joblib.dump(skala_Y, 'skala_Y.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mUL5Wr6oE6Gk"
      },
      "outputs": [],
      "source": [
        "X_mean = skala_X.mean_\n",
        "X_std_dev = skala_X.scale_\n",
        "Y_mean = skala_Y.mean_\n",
        "Y_std_dev = skala_Y.scale_\n",
        "print(\"Mean dari X (fitur):\", X_mean)\n",
        "print(\"Standard Deviation dari X (fitur):\", X_std_dev)\n",
        "print(\"Mean dari Y (target):\", Y_mean)\n",
        "print(\"Standard Deviation dari Y (target):\", Y_std_dev)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exporting the Best Model to a Specified Directory"
      ],
      "metadata": {
        "id": "RlkZco0iqWqa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HifbCMz7HWwK"
      },
      "outputs": [],
      "source": [
        "MODEL_DIR = tempfile.gettempdir()\n",
        "version = 1\n",
        "export_path = os.path.join(MODEL_DIR, str(version))\n",
        "print(f'export_path = {export_path}\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WChGCX2VKpPp"
      },
      "outputs": [],
      "source": [
        "model_terbaik.export(export_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Listing Exported Model Files and Displaying Model Details"
      ],
      "metadata": {
        "id": "46Gl6Bi_qjAt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NdD7KIIOHc2v"
      },
      "outputs": [],
      "source": [
        "!ls -l {export_path}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tIEBFhvKHg8v"
      },
      "outputs": [],
      "source": [
        "!saved_model_cli show --dir {export_path} --all"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Zipping the Exported Model and Downloading It from Google Colab"
      ],
      "metadata": {
        "id": "YR4Im3w2qocH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LdGSAsZpKxxd"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "from google.colab import files\n",
        "shutil.make_archive(\"/tmp/model\", 'zip', \"/tmp/1\")\n",
        "files.download(\"/tmp/model.zip\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Converting the Keras Model to TensorFlow Lite Format and Saving It"
      ],
      "metadata": {
        "id": "uykg02r5qu_4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K_YiImzF5ZP-"
      },
      "outputs": [],
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(model_terbaik)\n",
        "tflite_model = converter.convert()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PemqlYpu5ezA"
      },
      "outputs": [],
      "source": [
        "with open('model.tflite', 'wb') as f:\n",
        "    f.write(tflite_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "293X5nxsNhiS"
      },
      "outputs": [],
      "source": [
        "shutil.make_archive(\"/content/my_dir\", 'zip', \"/content/my_dir\")\n",
        "#files.download(\"/content/my_dir.zip\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}